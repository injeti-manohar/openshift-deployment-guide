= Setting up PostgreSQL
:toc:
:toc-title: ON THIS PAGE
:toclevels: 3
:section-refsig: Step

For simplicity, this guide describes how to deploy PostgreSQL using OpenShift in the same cluster as the example. But first, it is important to understand how to insure the proper level of isolation for each microservice in production.

== Ensuring the proper level of isolation

include::{partialsdir}/postgres-ovr.adoc[]

The Shopping Cart application only has one service that accesses the database, so any of these options would work. However, we’ll use a flexible setup, modeled on the second level of isolation, that makes it easy to add databases to the database pod as needed.

== Database schema overview

Lagom will automatically create database tables if they do not exist. However, we do not recommended this in production, since it's generally considered bad practice to allow an application database account to perform DDL statements. Instead, we'll manually create the database schema.

The shopping cart application uses Akka persistence with the https://github.com/dnvriend/akka-persistence-jdbc[Akka persistence JDBC] backend. This requires two tables: a journal table, which contains all entity events; and a snapshot table, which contains snapshots of the state every so many events. The schema for these tables on PostgreSQL can be found in the https://github.com/dnvriend/akka-persistence-jdbc/blob/master/src/test/resources/schema/postgres/postgres-schema.sql[Akka persistence JDBC repository].

In addition, Lagom needs an offset table, which is used to track the progress of read side processors and Kafka publishers through the event log. This schema is part of the Shopping Cart project, in `schemas/shopping-cart.sql`. We'll load the script using the `psql` client later.

== Deploy PostgreSQL with OpenShift [[deploy-oc]]

OpenShift provides images for deploying PostgreSQL out of the box, which simplifies pod creation. Detailed documentation on using this image can be found https://docs.openshift.com/container-platform/latest/using_images/db_images/postgresql.html[here]. Follow these steps to prepare the database:

:sectnums:

== Create a PostgreSQL pod [[create-pod]]

After you have connected to your OpenShift project, follow these steps to create the database pod:

.. Create an ephemeral database service called `postgresql` with the following command:
+
```sh
include::{examplesdir}/postgresql.sh[tag=new-app]
```
+
NOTE: This database is using ephemeral persistence, meaning that if the pod is restarted, all data will be lost. Refer to the PostgreSQL documentation for details on how to deploy persistent databases.
+
You should see a messge that the service was created. We did not set an `admin` password when creating the database because this would have hard coded it in the spec for the pod, making it readable to anyone that could read pods. Instead, we’re going to create a Kubernetes secret containing it, and then we’ll update the deployment to use that secret.

.. Create the secret with a random password:
+
```sh
include::{examplesdir}/postgresql.sh[tag=create-admin-password]
```


.. Patch the deployment config just created to use the admin password configured in the service.
+
```sh
include::{examplesdir}/postgresql.sh[tag=patch]
```

.. Use the following command to watch the database come up:
+
```sh
oc get pods -w
```
+
Depending on how quickly the new pod comes up, you might see the old database terminate as the new deployment config is applied.


== Provision the PostgreSQL database

We now need to create the database user, password, and the schema. To create our database, we’ll need to access PostgreSQL. There are two ways to do this:

* Port forwarding, where you open a port on your local machine, and then use the `psql` client installed on your local machine to connect to it.
* Shell into the PostgreSQL pod using `oc rsh`, and use the `psql` client installed on the pod to connect to the database.

We will use the first approach. It is simpler because the `psql` client on your local machine can access SQL scripts locally on your machine. To run a script when you shell into the pod, you would first need to copy the script there using `oc rsync`.

Follow these steps to provision the database:

.. Create the password, again using the secret API:
+
```sh
include::{examplesdir}/postgresql.sh[tag=create-user-password]
```

+
On success, the prompt responds that the password has been created.

.. Retrieve the secret.
+
```sh
oc get secret postgres-shopping-cart -o jsonpath='{.data.password}' | base64 --decode
```

.. Copy the decoded secret from the command window and save it for later use.

.. Start the port forward:
+
```sh
include::{examplesdir}/postgresql.sh[tag=port-forward]
```

+
This starts the forwarding in the background, it will output some logs when the tunnel is established, and each time it receives a new connection.
+
Now we can just run the `psql` command to connect as the PostgreSQL `admin` user. The PostgreSQL image we’re using is configured to trust all connections from `localhost`, and since the port forward command results in connections to it being made on the database as `localhost`, we can connect as any user without a password. We’ll directly feed it a script to create a database user, and grant that user access to just read/write operations on the database, so they won’t be able to execute any DDL statements.

.. Connect to the `postgres` default database:
+
```sh
include::{examplesdir}/postgresql.sh[tag=connect-database]
```
+
On success, a `postgres=#` prompt appears.

.. Using the secret you saved previously, substitute it for `<secret>` in the following command to create the user and password for the `shopping_cart` database:
+
CREATE USER shopping_cart WITH PASSWORD '<secret>';

.. Set the permission for this user and create the schema from the example script:
+
```sql
include::{examplesdir}/postgresql.sh[tag=create-ddl]
```
+
The prompt changes to reflect that you are connected to the `shopping_cart` database.

.. Type `\q` to exit.

.. Terminate the port forwarding session:
+
```sh
kill %1
```

:sectnums!:

== What's next

Next, follow the instructions for: xref:setting-up-kafka.adoc[Setting up Kafka].
